{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b23901",
   "metadata": {},
   "source": [
    "## **LangChain RAG/Multilingual**\n",
    "\n",
    "In this notebook, we're building a Retrieval-Augmented Generation (RAG) system using LangChain to power ALMA â€” an AI assistant specialized in health and wellness in **Spanish and English**. ALMA combines a GPT-4 language model with a Pinecone vector store to retrieve relevant knowledge and respond with context-aware, emotionally intelligent answers. The system also includes tools like a health calculator and a second vector index for matching helpful YouTube video clips. This setup creates a dynamic, human-like assistant that can both inform and guide users through natural conversation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328b7b0",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0dc2ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Built-in\n",
    "import os, time, tempfile, asyncio, re, json\n",
    "import edge_tts\n",
    "import pygame, speech_recognition as sr\n",
    "\n",
    "# Third-party\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pydub import AudioSegment\n",
    "from pinecone import Pinecone\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain\n",
    "from langsmith import Client\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.tracers.context import tracing_v2_enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bdc208",
   "metadata": {},
   "source": [
    "#### Load up Api keys\n",
    "We load the environment with te API keys and set up the path to use ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294565d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment \n",
    "load_dotenv(find_dotenv())\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Configure ffmpeg \n",
    "FFMPEG_PATH = os.getenv(\"FFMPEG_PATH\", r\"C:\\ffmpeg\\...\\bin\")\n",
    "os.environ[\"PATH\"] += os.pathsep + FFMPEG_PATH\n",
    "\n",
    "# LangSmith config\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ALMA-Assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4a73e",
   "metadata": {},
   "source": [
    "### LangChain + Pinecone brain setup for ALMA\n",
    "We connect to Pinecone using and select the \"alma-index\" for general health knowledge we extract from the transcripts. Then  we initialize OpenAI's embedding model, which turns text into vectors for similarity search. The vectorstore wraps that index, and the retriever lets ALMA search for the top 4 most relevant context chunks for each question. A second video_vectorstore connects to \"alma-video-index\", which contains timestamped YouTube clips, allowing ALMA to suggest helpful videos. Finally, the llm is ALMA's core intelligence, using GPT-4 to generate warm, personalized answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b82541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain Setup \n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"alma-index\")\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "\n",
    "vectorstore = PineconeVectorStore(index_name=\"alma-index\", embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "video_vectorstore = PineconeVectorStore(index_name=\"alma-video-index\", embedding=embeddings)\n",
    "video_retriever = video_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ae8b63",
   "metadata": {},
   "source": [
    "#### Set-up the tool\n",
    " We give ALMA a calculator brain for handling quick health computations like BMI, TDEE, and macros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa615e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alma_calculator(input_text: str, language: str = \"en\") -> str:\n",
    "    import re\n",
    "\n",
    "    def parse_kv(pairs):\n",
    "        return dict(re.findall(r'(\\w+)=([\\w.]+)', pairs))\n",
    "\n",
    "    input_text = input_text.lower().strip()\n",
    "\n",
    "    try:\n",
    "        if input_text.startswith(\"bmi\"):\n",
    "            args = parse_kv(input_text)\n",
    "            weight = float(args[\"weight\"])\n",
    "            height = float(args[\"height\"])\n",
    "            bmi = weight / (height ** 2)\n",
    "            return (\n",
    "                f\"Your BMI is approximately {bmi:.2f}.\" if language == \"en\"\n",
    "                else f\"Tu IMC es aproximadamente {bmi:.2f}.\"\n",
    "            )\n",
    "\n",
    "        elif input_text.startswith(\"tdee\"):\n",
    "            args = parse_kv(input_text)\n",
    "            weight = float(args[\"weight\"])\n",
    "            height = float(args[\"height\"]) * 100\n",
    "            age = int(args[\"age\"])\n",
    "            gender = args[\"gender\"]\n",
    "            activity = args[\"activity\"]\n",
    "\n",
    "            if gender == \"male\":\n",
    "                bmr = 10 * weight + 6.25 * height - 5 * age + 5\n",
    "            else:\n",
    "                bmr = 10 * weight + 6.25 * height - 5 * age - 161\n",
    "\n",
    "            activity_levels = {\n",
    "                \"sedentary\": 1.2,\n",
    "                \"light\": 1.375,\n",
    "                \"moderate\": 1.55,\n",
    "                \"active\": 1.725,\n",
    "                \"very active\": 1.9,\n",
    "            }\n",
    "\n",
    "            multiplier = activity_levels.get(activity, 1.55)\n",
    "            tdee = bmr * multiplier\n",
    "            return (\n",
    "                f\"Your estimated TDEE is about {tdee:.0f} calories per day based on a {activity} lifestyle.\"\n",
    "                if language == \"en\"\n",
    "                else f\"Tu TDEE estimado es de aproximadamente {tdee:.0f} calorÃ­as por dÃ­a con un estilo de vida {activity}.\"\n",
    "            )\n",
    "\n",
    "        elif input_text.startswith(\"macros\"):\n",
    "            args = parse_kv(input_text)\n",
    "            calories = float(args[\"calories\"])\n",
    "            carbs_pct = float(args[\"carbs\"])\n",
    "            protein_pct = float(args[\"protein\"])\n",
    "            fat_pct = float(args[\"fat\"])\n",
    "\n",
    "            carbs_g = (calories * carbs_pct / 100) / 4\n",
    "            protein_g = (calories * protein_pct / 100) / 4\n",
    "            fat_g = (calories * fat_pct / 100) / 9\n",
    "\n",
    "            if language == \"en\":\n",
    "                return (f\"Macro breakdown:\\n\"\n",
    "                        f\"â†’ Carbs: {carbs_g:.1f}g\\n\"\n",
    "                        f\"â†’ Protein: {protein_g:.1f}g\\n\"\n",
    "                        f\"â†’ Fat: {fat_g:.1f}g\")\n",
    "            else:\n",
    "                return (f\"DistribuciÃ³n de macronutrientes:\\n\"\n",
    "                        f\"â†’ Carbohidratos: {carbs_g:.1f}g\\n\"\n",
    "                        f\"â†’ ProteÃ­nas: {protein_g:.1f}g\\n\"\n",
    "                        f\"â†’ Grasas: {fat_g:.1f}g\")\n",
    "\n",
    "        else:\n",
    "            return (\n",
    "                \"Sorry, I didnâ€™t recognize that calculation type. Try starting with 'bmi', 'tdee', or 'macros'.\"\n",
    "                if language == \"en\"\n",
    "                else \"Lo siento, no reconocÃ­ ese tipo de cÃ¡lculo. Intenta empezar con 'bmi', 'tdee' o 'macros'.\"\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"âš ï¸ There was an error processing your request: {e}\"\n",
    "            if language == \"en\"\n",
    "            else f\"âš ï¸ Hubo un error al procesar tu solicitud: {e}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90e98a",
   "metadata": {},
   "source": [
    "#### Lets make ALMA alive\n",
    "In this part we create ALMAS personality using GPT-4 and the right prompt. We set up the Langchain tool (calculator) and a LangChain agent that decides to use that calculator or respond on its own. Then we give ALMA a voice so the user can choose, after a welcome message, whether they would prefer to talk or type. ALMA can suggest a video based on the question but that video needs to be relevant so the the similarity score must be high enough.\n",
    "\n",
    "After this, we have our main loop, this is the engine of ALMAâ€™s interaction:\n",
    "Every time you ask a question:\n",
    " - ALMA listens (or waits for typed input)\n",
    " - If itâ€™s a calculator-type question â†’ uses the Agent (with alma_calculator)\n",
    " - Otherwise â†’ retrieves context documents, builds a personalized prompt, and sends it to GPT-4\n",
    " - If a highly relevant video matches the query, GPT-4 decides whether to suggest it (based on its content and tags)\n",
    "- ALMA prints the answer (and speaks it, if in voice mode)\n",
    "- Everything is logged to chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691f76ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ¿ Welcome to ALMA / Bienvenido a ALMA ğŸŒ¿\n",
      "Hi, I'm ALMA â€” your AI companion for better living.\n",
      "\n",
      "I'm here to help you improve your sleep, nutrition, mood, energy, and long-term well-being â€” all grounded in science and tailored to your needs.\n",
      "\n",
      "Estoy aquÃ­ para ayudarte a mejorar tu sueÃ±o, nutriciÃ³n, estado de Ã¡nimo, energÃ­a y bienestar a largo plazo â€” con base cientÃ­fica y adaptado a ti.\n",
      "\n",
      "Let's begin. / Empecemos. ğŸ’¬\n",
      "\n",
      "â„¹ï¸ Video similarity (0.75) below threshold.\n",
      "\n",
      "ğŸ’¬ ALMA dice:\n",
      " Me alegra mucho que me hayas preguntado eso. La fatiga puede ser resultado de diversas causas. Por ejemplo, puede deberse a una alimentaciÃ³n inadecuada, insomnio, falta de ejercicio o estrÃ©s. Incluso las preocupaciones emocionales, como la depresiÃ³n y la ansiedad, pueden hacer que te sientas cansado. \n",
      "\n",
      "Un primer paso podrÃ­a ser reflexionar sobre estas Ã¡reas de tu vida para ver si hay alguno que parezca estar fuera de equilibrio. Por ejemplo, Â¿has estado comiendo de manera saludable y equilibrada? Â¿Duermes lo suficiente cada noche? Â¿Experimentas estrÃ©s en tu vida diaria? Â¿CÃ³mo te encuentras emocionalmente? \n",
      "\n",
      "Estas reflexiones pueden darte una idea de por dÃ³nde empezar para mejorar tu energÃ­a. Sin embargo, es importante recordar que si la fatiga no mejora o es severa, es recomendable que consultes a un profesional de la salud.\n",
      "\n",
      "Para poder ayudarte de manera mÃ¡s especÃ­fica, Â¿serÃ­a posible que me compartas un poco mÃ¡s sobre tu estilo de vida y tus hÃ¡bitos? Es Ãºtil reflexionar sobre eso cuando estamos tratando de encontrar soluciones a problemas complejos como la fatiga.\n",
      "â„¹ï¸ Video similarity (0.76) below threshold.\n",
      "\n",
      "ğŸ’¬ ALMA dice:\n",
      " Me alegra mucho que me hayas preguntado eso. SegÃºn las tendencias de alimentaciÃ³n que hemos discutido, parece que podrÃ­as beneficiarte de una dieta mÃ¡s balanceada, rica en frutas, verduras, proteÃ­nas magras y granos enteros. Comer un rango diverso de alimentos puede ayudar a asegurar que estÃ¡s obteniendo una mezcla saludable de nutrientes, lo que es fundamental para el bienestar general y la vitalidad.\n",
      "\n",
      "Por ejemplo, si estÃ¡s comiendo muchas comidas procesadas, podrÃ­as mejorar tu salud cambiÃ¡ndolas por comidas caseras hechas con ingredientes frescos. Si estÃ¡s saltÃ¡ndote comidas, considera establecer un horario de alimentaciÃ³n regular para ayudar a regular el metabolismo de tu cuerpo. Y si no consumes suficientes frutas y verduras, podrÃ­a ser Ãºtil introducir mÃ¡s en tu dieta para la variedad de vitaminas y minerales que aportan.\n",
      "\n",
      "Recuerda que todos somos diferentes, y lo que funciona para una persona puede no funcionar para otra. Â¿Ha habido alguna vez en tu vida en que hayas hecho cambios en tu alimentaciÃ³n que hayan afectado positivamente a tu salud y bienestar? Pueden ser muy Ãºtiles al momento de crear un plan personalizado para ti.\n",
      "â„¹ï¸ Video similarity (0.77) below threshold.\n",
      "\n",
      "ğŸ’¬ ALMA dice:\n",
      " Has planteado algo realmente importante. Dormir mal puede tener un impacto significativo en tu salud y bienestar. No sÃ³lo puede afectar a tu energÃ­a y estado de Ã¡nimo, sino tambiÃ©n a funciones cruciales como tu sistema inmunolÃ³gico o procesos metabÃ³licos. De hecho, la privaciÃ³n de sueÃ±o se ha vinculado a problemas de salud como la obesidad, la diabetes y enfermedades cardiovasculares. En tÃ©rminos de bienestar mental, un sueÃ±o inadecuado tambiÃ©n puede contribuir a problemas como la ansiedad o la depresiÃ³n. \n",
      "\n",
      "Por lo tanto, es vital establecer buenas rutinas de sueÃ±o y tratar cualquier problema de sueÃ±o que tengas. Â¿PodrÃ­as compartir conmigo tus hÃ¡bitos de sueÃ±o actuales? Esto podrÃ­a ayudarnos a identificar cualquier Ã¡rea de mejora. \n",
      "â„¹ï¸ Video similarity (0.71) below threshold.\n",
      "\n",
      "ğŸ’¬ ALMA dice:\n",
      " Esa es una pregunta muy valiosa. Priorizar depende mucho de tu situaciÃ³n individual y tus objetivos personales. Te recomendarÃ­a que te hagas las siguientes preguntas:\n",
      " \n",
      "- Â¿QuÃ© hÃ¡bitos de salud y bienestar me gustarÃ­a cambiar o mejorar? \n",
      "- Â¿QuÃ© Ã¡reas de mi vida siento que estÃ¡n teniendo el mayor impacto en mi bienestar y salud actualmente? \n",
      "- Â¿CuÃ¡les son los primeros pasos mÃ¡s realistas y alcanzables que puedo dar hacia estos cambios? \n",
      "\n",
      "Esto te ayudarÃ¡ a identificar lo que deberÃ­as priorizar. Luego, puedes comenzar a explorar acciones especÃ­ficas que puedes tomar para hacer estos cambios.\n",
      "\n",
      "Pero siempre recuerda: a veces, los cambios pequeÃ±os y consistentes pueden tener un impacto mayor y mÃ¡s duradero que los cambios grandes y repentinos.\n",
      "   \n",
      "Â¿PodrÃ­as compartir cuÃ¡l es el Ã¡rea de tu vida que crees que necesita mÃ¡s atenciÃ³n? Esto podrÃ­a ayudarnos a entender mejor tus hÃ¡bitos y a guiarnos hacia el siguiente paso.\n",
      "ğŸŒ™ ALMA dice: CuÃ­date. EstarÃ© aquÃ­ cuando me necesites nuevamente.\n"
     ]
    }
   ],
   "source": [
    "# Prompt Template \n",
    "prompt_en = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are ALMA â€” a warm, intelligent, and caring AI assistant specialized in health, nutrition, sleep, mental wellness, and healthy aging.\n",
    "\n",
    "You speak to the user like a thoughtful health coach: clear, knowledgeable, emotionally intelligent, and supportive.\n",
    "\n",
    "When responding:\n",
    "- If the user input is a **question**, begin with one of these:\n",
    "    - \"Youâ€™ve brought up something really meaningful.\"\n",
    "    - \"I'm really glad you asked that.\"\n",
    "    - \"Thatâ€™s such an important question.\"\n",
    "   \n",
    "- If the user input is a **statement** or expression of emotion, begin with one of these:\n",
    "    - \"Letâ€™s take a closer look together.\"\n",
    "    - \"Hereâ€™s something that might help you.\"\n",
    "    - \"Thanks for sharing that with me.\"\n",
    "- If you're unsure, just start naturally without forcing a phrase.\n",
    "\n",
    "Your priority is to **give a clear, grounded, and caring answer first** â€” with insights the user can act on.\n",
    "\n",
    "If you genuinely have more helpful information to offer, end your response with a warm, relevant follow-up question â€” and explain why you're asking it. For example:\n",
    "- â€œThat might help us understand your patterns better.â€\n",
    "- â€œThis could help guide the next step.â€\n",
    "- â€œItâ€™s often helpful to reflect on that when building new habits.â€\n",
    "\n",
    "Answer using only the information in the provided context. Do not rely on outside knowledge. \n",
    "If you cannot find the answer in the context, say \"Iâ€™m not sure based on what I know, but I can help you explore something else.\"\n",
    "\n",
    "If you find a video in the context that directly supports or enhances your answer, it's highly encouraged to offer it to the user.\n",
    "\n",
    "Say this:\n",
    "> â€œWould you like to watch a video that explains this further? I found one that seems really helpful.â€\n",
    "\n",
    "Only offer a video if it clearly reinforces your answer or adds value.\n",
    "---\n",
    "{context}\n",
    "---\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "prompt_es = ChatPromptTemplate.from_template(\"\"\"\n",
    "Eres ALMA â€” una asistente de inteligencia artificial cÃ¡lida, inteligente y empÃ¡tica, especializada en salud, nutriciÃ³n, sueÃ±o, bienestar mental y envejecimiento saludable.\n",
    "\n",
    "Hablas con el usuario como una coach de salud reflexiva: clara, conocedora, emocionalmente inteligente y siempre comprensiva.\n",
    "\n",
    "Al responder:\n",
    "- Si la entrada del usuario es una **pregunta**, comienza con una de estas frases:\n",
    "    - \"Has planteado algo realmente importante.\"\n",
    "    - \"Me alegra mucho que me hayas preguntado eso.\"\n",
    "    - \"Esa es una pregunta muy valiosa.\"\n",
    "\n",
    "- Si la entrada del usuario es una **afirmaciÃ³n** o una expresiÃ³n emocional, comienza con una de estas:\n",
    "    - \"Echemos un vistazo mÃ¡s profundo juntas/os.\"\n",
    "    - \"Esto podrÃ­a ayudarte.\"\n",
    "    - \"Gracias por compartirlo conmigo.\"\n",
    "\n",
    "- Si no estÃ¡s segura, comienza de forma natural sin forzar ninguna frase.\n",
    "\n",
    "Tu prioridad es **dar una respuesta clara, fundamentada y empÃ¡tica** â€” con ideas prÃ¡cticas que el usuario pueda aplicar.\n",
    "\n",
    "Si genuinamente tienes mÃ¡s informaciÃ³n Ãºtil que ofrecer, termina tu respuesta con una pregunta de seguimiento cÃ¡lida y relevante â€” y explica por quÃ© la haces. Por ejemplo:\n",
    "- â€œEsto podrÃ­a ayudarnos a entender mejor tus hÃ¡bitos.â€\n",
    "- â€œPodrÃ­a guiarnos hacia el siguiente paso.â€\n",
    "- â€œEs Ãºtil reflexionar sobre eso cuando estamos construyendo nuevos hÃ¡bitos.â€\n",
    "\n",
    "Responde Ãºnicamente utilizando la informaciÃ³n proporcionada en el contexto. No utilices conocimientos externos.\n",
    "Si no puedes encontrar la respuesta en el contexto, di: \"No estoy segura basÃ¡ndome en lo que sÃ©, pero puedo ayudarte a explorar otras opciones.\"\n",
    "\n",
    "Si encuentras un video en el contexto que refuerce o enriquezca directamente tu respuesta, se recomienda ofrecÃ©rselo al usuario.\n",
    "\n",
    "Di esto:\n",
    "> â€œÂ¿Te gustarÃ­a ver un video que explique esto con mÃ¡s detalle? EncontrÃ© uno que podrÃ­a ayudarte.â€\n",
    "\n",
    "Solo ofrece un video si realmente aporta valor o refuerza tu respuesta.\n",
    "\n",
    "---\n",
    "{context}\n",
    "---\n",
    "\n",
    "Pregunta:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "calc_tool = Tool(\n",
    "    name=\"HealthCalculator\",\n",
    "    func=alma_calculator,\n",
    "    description=(\n",
    "        \"Use this to calculate BMI, TDEE, or macronutrient distribution.\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"- bmi weight=70 height=1.75\\n\"\n",
    "        \"- tdee weight=70 height=1.75 age=30 gender=female activity=moderate\\n\"\n",
    "        \"- macros calories=2000 carbs=50 protein=25 fat=25\"\n",
    "    )\n",
    ")\n",
    "\n",
    "tools = [calc_tool]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "async def speak_alma_edge(text):\n",
    "    # Choose voice model based on language\n",
    "    voice = \"en-US-JennyNeural\" if language == \"en\" else \"es-ES-ElviraNeural\"\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_file:\n",
    "        temp_path = temp_file.name\n",
    "\n",
    "    # Use selected voice with slightly faster speed\n",
    "    communicate = edge_tts.Communicate(text=text, voice=voice, rate=\"+10%\")\n",
    "    await communicate.save(temp_path)\n",
    "\n",
    "    # Wait until file is fully written\n",
    "    timeout = 7\n",
    "    start = time.time()\n",
    "    while not os.path.exists(temp_path):\n",
    "        if time.time() - start > timeout:\n",
    "            print(\"âš ï¸ Timed out waiting for audio file.\")\n",
    "            return\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # Play it with pygame\n",
    "    try:\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(temp_path)\n",
    "        pygame.mixer.music.play()\n",
    "\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            await asyncio.sleep(0.3)\n",
    "\n",
    "        pygame.mixer.music.stop()\n",
    "        pygame.mixer.quit()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Audio playback failed: {e}\")\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(temp_path)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not delete audio file: {e}\")\n",
    "def listen_to_user():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"\\nğŸ¤ Listening... (say 'exit' to quit)\" if language == \"en\" else \"\\nğŸ¤ Escuchando... (di 'salir' para terminar)\")\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio, language=\"es-ES\" if language == \"es\" else \"en-US\")\n",
    "        print(f\"\\nğŸ’¬ You said: {text}\" if language == \"en\" else f\"\\nğŸ’¬ Dijiste: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"âŒ Sorry, I didn't catch that.\" if language == \"en\" else \"âŒ Lo siento, no entendÃ­ eso.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"âŒ Speech service error.\" if language == \"en\" else \"âŒ Error en el servicio de reconocimiento de voz.\")\n",
    "        return \"\"\n",
    "\n",
    "#  Welcome Message & Language Selection \n",
    "print(\"\"\"\n",
    "ğŸŒ¿ Welcome to ALMA / Bienvenido a ALMA ğŸŒ¿\n",
    "Hi, I'm ALMA â€” your AI companion for better living.\n",
    "\n",
    "I'm here to help you improve your sleep, nutrition, mood, energy, and long-term well-being â€” all grounded in science and tailored to your needs.\n",
    "\n",
    "Estoy aquÃ­ para ayudarte a mejorar tu sueÃ±o, nutriciÃ³n, estado de Ã¡nimo, energÃ­a y bienestar a largo plazo â€” con base cientÃ­fica y adaptado a ti.\n",
    "\n",
    "Let's begin. / Empecemos. ğŸ’¬\n",
    "\"\"\")\n",
    "\n",
    "language = input(\"ğŸŒ Choose your language / Elige tu idioma (en/es): \").strip().lower()\n",
    "voice_mode = input(\"ğŸ™ï¸ Would you like to talk to ALMA using your voice? / Â¿Quieres hablar con ALMA usando tu voz? (y/n): \").strip().lower() == \"y\"\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "def get_top_video_suggestion(query: str, min_similarity: float = 0.85):\n",
    "    results = video_vectorstore.similarity_search_with_score(query, k=2)\n",
    "    if not results:\n",
    "        return None\n",
    "\n",
    "    top_doc, score = results[0]\n",
    "    if score < min_similarity:\n",
    "        print(f\"â„¹ï¸ Video similarity ({score:.2f}) below threshold.\")\n",
    "        return None\n",
    "\n",
    "    metadata = top_doc.metadata\n",
    "    return {\n",
    "        \"title\": metadata.get(\"video_title\", \"\"),\n",
    "        \"url\": metadata.get(\"video_url\", \"\"),\n",
    "        \"snippet\": top_doc.page_content[:300] + \"...\",\n",
    "        \"tags\": metadata.get(\"tags\", []),\n",
    "        \"video_id\": metadata.get(\"video_id\", \"\")  \n",
    "    }\n",
    "\n",
    "# Keep track of shown videos\n",
    "shown_video_ids = set()\n",
    "\n",
    "# MAIN LOOP\n",
    "async def main():\n",
    "    while True:\n",
    "        user_input = listen_to_user().strip() if voice_mode else input(\n",
    "            \"\\nğŸ’¬ Your question for ALMA (or type 'exit'): \" if language == \"en\"\n",
    "            else \"\\nğŸ’¬ Tu pregunta para ALMA (o escribe 'salir'): \"\n",
    "        ).strip()\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"salir\"]:\n",
    "            farewell = (\n",
    "                \"Take care. I'll be here when you need me again.\"\n",
    "                if language == \"en\"\n",
    "                else \"CuÃ­date. EstarÃ© aquÃ­ cuando me necesites nuevamente.\"\n",
    "            )\n",
    "            print(\"ğŸŒ™ \" + (\"ALMA says:\" if language == \"en\" else \"ALMA dice:\"), farewell)\n",
    "            if voice_mode:\n",
    "                await speak_alma_edge(farewell)\n",
    "            break\n",
    "\n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        # Build memory-aware context\n",
    "        if chat_history:\n",
    "            full_question = \"Conversation so far:\\n\" + \"\\n\".join(\n",
    "                [f\"User: {q}\\nALMA: {a}\" for q, a in chat_history[-3:]]\n",
    "            ) + f\"\\nUser: {user_input}\"\n",
    "        else:\n",
    "            full_question = user_input\n",
    "\n",
    "        docs = retriever.invoke(full_question)\n",
    "        context_parts, total_chars, max_chars = [], 0, 3000\n",
    "        for doc in docs:\n",
    "            text = doc.page_content.strip()\n",
    "            if total_chars + len(text) <= max_chars:\n",
    "                context_parts.append(text)\n",
    "                total_chars += len(text)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        prompt = prompt_en if language == \"en\" else prompt_es\n",
    "        formatted_prompt = prompt.format(context=context, question=user_input)\n",
    "\n",
    "        # Decide if using agent or LLM\n",
    "        try:\n",
    "            if any(kw in user_input.lower() for kw in [\"bmi\", \"calculate\", \"how many\", \"how much\", \"percent\", \"+\", \"-\", \"*\", \"/\"]):\n",
    "                agent_response = agent.invoke({\"input\": user_input})\n",
    "                response = agent_response.get(\"output\")\n",
    "                if not response:\n",
    "                    response = (\n",
    "                        \"I'm not sure how to calculate that.\"\n",
    "                        if language == \"en\"\n",
    "                        else \"No estoy segura de cÃ³mo calcular eso.\"\n",
    "                    )\n",
    "                    print(\"âš ï¸ Agent returned no output.\")\n",
    "            else:\n",
    "                response = llm.invoke(formatted_prompt).content\n",
    "        except OutputParserException:\n",
    "            response = (\n",
    "                \"I tried to use a tool to answer that, but couldn't parse the response properly. Could you rephrase?\"\n",
    "                if language == \"en\"\n",
    "                else \"IntentÃ© usar una herramienta para responder, pero no pude procesar bien la respuesta. Â¿PodrÃ­as reformularla?\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            response = (\n",
    "                f\"Something went wrong: {e}\"\n",
    "                if language == \"en\"\n",
    "                else f\"Algo saliÃ³ mal: {e}\"\n",
    "            )\n",
    "\n",
    "        # Suggest relevant video\n",
    "        suggestion = get_top_video_suggestion(user_input)\n",
    "        if suggestion and suggestion[\"video_id\"] not in shown_video_ids:\n",
    "            video_prompt_en = f\"\"\"\n",
    "This is the user question: \"{user_input}\"\n",
    "\n",
    "This is your response:\n",
    "{response}\n",
    "\n",
    "And here is a short video clip that matches it:\n",
    "Title: {suggestion['title']}\n",
    "Snippet: \"{suggestion['snippet']}\"\n",
    "Tags: {', '.join(suggestion['tags'])}\n",
    "\n",
    "If the clip supports or enriches your answer, add a short, warm suggestion to watch the video, like:\n",
    "â€œWould you like to watch a video that explains this further? I found one that seems really helpful.â€\n",
    "\n",
    "Then show the video link and tags. If the clip isn't relevant, say nothing.\n",
    "\"\"\"\n",
    "\n",
    "            video_prompt_es = f\"\"\"\n",
    "Esta es la pregunta del usuario: \"{user_input}\"\n",
    "\n",
    "Esta es tu respuesta:\n",
    "{response}\n",
    "\n",
    "Y aquÃ­ hay un clip de video que coincide con el tema:\n",
    "TÃ­tulo: {suggestion['title']}\n",
    "Fragmento: \"{suggestion['snippet']}\"\n",
    "Etiquetas: {', '.join(suggestion['tags'])}\n",
    "\n",
    "Si este clip apoya o mejora tu respuesta, aÃ±ade una sugerencia cÃ¡lida como:\n",
    "â€œÂ¿Te gustarÃ­a ver un video que explique esto con mÃ¡s detalle? EncontrÃ© uno que podrÃ­a ayudarte.â€\n",
    "\n",
    "Luego muestra el enlace del video y las etiquetas. Si no es relevante, no digas nada.\n",
    "\"\"\"\n",
    "            video_prompt = video_prompt_en if language == \"en\" else video_prompt_es\n",
    "            try:\n",
    "                video_message = llm.invoke(video_prompt).content\n",
    "                if video_message.strip():\n",
    "                    response += \"\\n\\n\" + video_message\n",
    "                    response += f\"\"\"\\nğŸ¥ **{suggestion['title']}**\\n{suggestion['url']}\\n_{', '.join(suggestion['tags'])}_\"\"\"\n",
    "                    shown_video_ids.add(suggestion[\"video_id\"])\n",
    "            except Exception as e:\n",
    "                print(\"âš ï¸ Video suggestion failed:\", e)\n",
    "\n",
    "        # Output\n",
    "        print(\"\\nğŸ’¬ ALMA says:\\n\" if language == \"en\" else \"\\nğŸ’¬ ALMA dice:\\n\", response)\n",
    "        if voice_mode:\n",
    "            await speak_alma_edge(response)\n",
    "\n",
    "        # Save to chat history\n",
    "        chat_history.append((user_input, response))\n",
    "\n",
    "# RUN WRAPPED WITH TRACING\n",
    "async def run_alma():\n",
    "    with tracing_v2_enabled(project_name=\"ALMA-Assistant\"):\n",
    "        await main()\n",
    "\n",
    "# Call the main run\n",
    "await run_alma()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
